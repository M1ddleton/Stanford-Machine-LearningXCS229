\item \points{1c} For a training set $\{(x^{(i)}, y^{(i)});\, i=1,\ldots,\nexp\}$, let the log-likelihood of an example be $\log p(y^{(i)} \vert  x^{(i)}; \theta)$. By taking the derivative of the log-likelihood with respect to $\theta_j$, derive the stochastic gradient ascent update rule for learning using a GLM model with Poisson responses $y$ and the canonical response function.\\
